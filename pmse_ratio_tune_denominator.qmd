---
title: "pmse_ratio_tune_denominator"
format: pdf
---

Implementing a version of pMSE ratio where we tune the denominator cp for each iteration, 

```{r}
library(tidyverse)
library(ipumsr)
library(srvyr)
library(tidysynthesis)
library(parsnip)
library("data.table")
library(recipes)
library(devtools)
load_all("../syntheval")
#library(syntheval)
library(dials)
library(tune)
library(gtools)
library(MASS)
library(caret)
library(gt)
library(ggpubr)
source("add_pmse_ratio_size.R")
library(rlang)
set.seed(78483)
```

```{r}
process_data <- function(df){
  df <- as.data.frame(unclass(df),stringsAsFactors=TRUE)
  df$pov <- as.factor(df$pov)
  df$BLACK <- as.factor(df$BLACK)
  order = c("BLACK", "pov", "SEX", "EMPSTAT", "EDUC", "HCOVANY", "VETSTAT", "FTOTINC", "AGE")
  df <- df %>%
    dplyr::select(order)
  df
}

data_mi <- read_csv("data/data_mi.csv")
data_mi <- process_data(data_mi)
```

```{r}
synth_good <- read_csv("data/good_synth_black.csv")
synth_good <- process_data(synth_good)

synth_fair <- read_csv("data/synth_75_black.csv")
synth_fair <- process_data(synth_fair)

synth_poor <- read_csv("data/med_synth_black.csv")
synth_poor <- process_data(synth_poor)

synth_bad <- read_csv("data/bad_synth_black.csv")
synth_bad <- process_data(synth_bad)
```

```{r}
calc_disc <- function(discriminator){
  # Evaluate discriminant-based metrics on the data using tree-based model
  tree_mod <- decision_tree(cost_complexity = tune()) %>%
    set_mode(mode = "classification") %>%
    set_engine(engine = "rpart")
  
  rpart_rec <- recipe(.source_label ~ ., data = discriminator$combined_data)
  
  grid = grid_regular(cost_complexity(), levels= 10)
  
  # set up discriminator
  d <- discriminator %>%
    add_propensities_tuned(
      grid = grid, 
      recipe = rpart_rec,
      spec = tree_mod
    )
  return(d)
}
```

Calculate all discriminator models for majority and minority, discriminating against all levels of good-bad synthesis
```{r}
calc_maj_min_res <- function(synth, conf){
  conf_not_black <- conf %>%
    filter(BLACK == 0)
  synth_not_black <- synth %>%
      filter(BLACK == 0)
  disc_not_black <- discrimination(synth_not_black, conf_not_black)
  # fit model wtih pmse to our not Black sub-dataset
  res_not_black <- calc_disc(disc_not_black)
  
  # create Black sub-dataset
  conf_black <- conf %>%
      filter(BLACK == 1)
  synth_black <- synth %>%
      filter(BLACK == 1)
  disc_black <- discrimination(synth_black, conf_black)
  
  # fit model wtih pmse to Black sub-dataset
  res_black <- calc_disc(disc_black)
  return(list(res_not_black, res_black))
}
```

```{r}
list_bad <- calc_maj_min_res(synth_bad, data_mi)
res_not_black_bad = list_bad[[1]] %>%
  add_pmse()
res_black_bad = list_bad[[2]] %>%
  add_pmse()

list_poor <- calc_maj_min_res(synth_poor, data_mi)
res_not_black_poor = list_poor[[1]] %>%
  add_pmse()
res_black_poor = list_poor[[2]] %>% 
  add_pmse()

list_fair <- calc_maj_min_res(synth_fair, data_mi)
res_not_black_fair = list_fair[[1]] %>%
  add_pmse()
res_black_fair = list_fair[[2]] %>%
  add_pmse()

list_good <- calc_maj_min_res(synth_good, data_mi)
res_not_black_good = list_good[[1]] %>%
  add_pmse()
res_black_good = list_good[[2]] %>%
  add_pmse()
```

```{r}
null_pmse_refit <- function(data, size){
  calc_pmse <- function(propensities) {
      
      # calculate the expected propensity
      prop_synthetic <- propensities %>%
        dplyr::summarize("prop_synthetic" = list(c(sum(.data$.source_label == "synthetic")/dplyr::n()))) %>%
        dplyr::pull(prop_synthetic)
      
      propensities_vec <- propensities %>%
        dplyr::summarise(".pred_synthetic" = list(c(.pred_synthetic))) %>%
        dplyr::pull(.pred_synthetic)
      
      # function for pmse
      pmse_func <- function(propensities_vec, prop_synthetic){
        mean((propensities_vec - prop_synthetic)^2)
      }
      
      # calculate the observed pMSE
      #pmse <- mapply(pmse_func, propensities_vec, prop_synthetic)
      pmse <- purrr::map2_dbl(
        .x = propensities_vec,
        .y = prop_synthetic,
        .f = pmse_func
      )
      return(pmse)
  }
  
  resample <- function(data){
    bootstrap_sample <- list(dplyr::bind_cols(
      data %>%
        dplyr::filter(.data$.source_label == "original") %>%
        dplyr::slice_sample(n = nrow(data), replace = TRUE) %>%
        dplyr::select(-".source_label"),
      data %>%
        dplyr::select(".source_label")))
      
      bootstrap_sample = dplyr::bind_rows(bootstrap_sample)
  } 
  
  pmse_null_overall <- vector(mode = "numeric", length = size)
  pmse_null_training <- vector(mode = "numeric", length = size)
  pmse_null_testing <- vector(mode = "numeric", length = size)
  cp_params <- vector(mode = "numeric", length = size)
  
  for (a in 1:size){
    # bootstrap sample original observations to equal the size of the combined 
    # data, with a vector of one set of observations per grouping variable (?)
    # append the original labels so the proportions match
    bootstrap_sample <- resample(data$combined_data)
        
    # make training/testing split 
    data_split <- rsample::initial_split(
        data = bootstrap_sample,
        prop = prop,
        strata = ".source_label" # NOTE: Should this also be stratified by group?
    )
    
    # fit model, retraining cp
    training = rsample::training(data_split)
    training_synth = training[training$.source_label == "synthetic",]
    training_conf = training[training$.source_label == "original",]
    
    disc_sample <- calc_disc(discrimination(training_synth, training_conf))
    fitted_model = disc_sample$discriminator
    
    cp_params[a] = quo_get_expr(extract_spec_parsnip(fitted_model)$args$cost_complexity)
    print(paste0("cp: ", quo_get_expr(extract_spec_parsnip(fitted_model)$args$cost_complexity)))
  
    # calculate the propensities
    propensities_df <- dplyr::bind_cols(
      stats::predict(fitted_model, new_data = data$combined_data, type = "prob")[, ".pred_synthetic"],
      data$combined_data
    ) %>%
        dplyr::mutate(
          .sample = dplyr::if_else(
            dplyr::row_number() %in% data_split$in_id, 
            true = "training", 
            false = "testing"
          )
            )
          
    pmse_null_testing[a] <- list(propensities_df %>%
                                  dplyr::filter(.data$.sample == "testing") %>%
                                  calc_pmse())
  }
  
  # find the mean of the bootstrapped pMSEs
  mean_null_pmse_testing <- colMeans(do.call(rbind,pmse_null_testing))
    
  list(mean_null_pmse_testing, cp_params)
}

```

Using null pMSE function (which refits for every component of denominator) to calculate 5 component denominators, also printing the cp terms
```{r}
times = 5 
prop = 3/4
null_pmse_black_bad <- null_pmse_refit(res_black_bad, times)  
cp_black_bad <- null_pmse_black_bad[2]
null_pmse_black_bad <- null_pmse_black_bad[[1]]

null_pmse_not_black_bad <- null_pmse_refit(res_not_black_bad, times) 
cp_not_black_bad <- null_pmse_not_black_bad[2]
null_pmse_not_black_bad <- null_pmse_not_black_bad[[1]]


null_pmse_black_poor <- null_pmse_refit(res_black_poor, times)  
cp_black_poor <- null_pmse_black_poor[2]
null_pmse_black_poor <- null_pmse_black_poor[[1]]

null_pmse_not_black_poor <- null_pmse_refit(res_not_black_poor, times)  
cp_not_black_poor <- null_pmse_not_black_poor[2]
null_pmse_not_black_poor <- null_pmse_not_black_poor[[1]]


null_pmse_black_fair <- null_pmse_refit(res_black_fair, times)  
cp_black_fair <- null_pmse_black_fair[2]
null_pmse_black_fair <- null_pmse_black_fair[[1]]

null_pmse_not_black_fair <- null_pmse_refit(res_not_black_fair, times)
cp_not_black_fair <- null_pmse_not_black_fair[2]
null_pmse_not_black_fair <- null_pmse_not_black_fair[[1]]


null_pmse_black_good <- null_pmse_refit(res_black_good, times)  
cp_black_good <- null_pmse_black_good[2]
null_pmse_black_good <- null_pmse_black_good[[1]]

null_pmse_not_black_good <- null_pmse_refit(res_not_black_good, times)  
cp_not_black_good <- null_pmse_not_black_good[2]
null_pmse_not_black_good <- null_pmse_not_black_good[[1]]
```

Using these null pmse lists, calculate pMSE ratios
```{r}
cp_not_black_good

```


