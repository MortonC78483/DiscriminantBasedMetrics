---
title: "jan_update_2.3"
format:
  html:
    self-contained: true
    theme: default
    code-fold: true
    code-summary: "Show the code"
    embed-resoures: true
    toc: true
---

```{r}
library(tidyverse)
library(ipumsr)
library(srvyr)
library(tidysynthesis)
library(parsnip)
library("data.table")
library(recipes)
library(devtools)
load_all('../../syntheval')
library(syntheval)
library(dials)
library(tune)
library(gtools)
library(MASS)
library(caret)
library(gt)
library(ggpubr)

set.seed(1)
```

This piece of the January Update concerns the second part of the project.

In this project, I'm trying to find ways to detect when synthesized data isn't just generally a poor match for original confidential data, but when it specifically matches confidential data less for a minority group.

In the previous part of the project, I demonstrated that pairwise modeling can show us when a dataset is poorly matched to a specific minority group, but that it does not work for binary 

In this part of the project, I will describe another way to detect whether synthetic data are a good match to confidential data for majority/minority groups. This way involves (1) examining propensity scores on a model fit to the full synthetic and confidential datasets, and splitting these scores out by group of interest, and (2) fitting different models to the synthetic and confidential data by group. In both cases, discriminant-based metrics can be calculated and compared.

These discriminant-based metrics give us differences in utility by group either from one or multiple models fit to discriminate between synthetic and confidential data. The differences in these scores may or may not be large compared to what we would expect by random chance when dividing up the given synthetic and confidential data into majority/minority splits. To get at the significance of the differences in discriminant-based metrics by group, I performed permutation tests.

I tested these procedures on synthetic data created from all confidential data ("good" synthetic data) and from only the majority group of the confidential data ("bad" synthetic data) for poverty status as the majority/minority indicator variable.

I found that the first method, in which only one model is used, did not pick up on any biases in the "good" synthetic data (the difference between metrics on majority and minority groups was well in range of my perturbation trials). However, the second method picked up a bias in the "good" synthesis towards the majority group, where it is less easy for the models to discriminate between the synthetic data and the confidential data for the majority group. This was significant under my permutation tests. The second method is the only method, out of both this section and part 2, to pick up on the fact that the "good" synthesis may actually still be biased towards the majority group. To me, this suggests that it is the best method (of any of the things I've tried thus far) to find out whether a synthetic dataset has higher utility for a majority group in the data.

```{r}
# load data
data_mi <- read_csv("../data/data_mi.csv")
data_mi <- as.data.frame(unclass(data_mi),stringsAsFactors=TRUE)
data_mi$pov <- as.factor(data_mi$pov)
data_mi$BLACK <- as.factor(data_mi$BLACK)
```

```{r}
# function that takes start data and confidential data, and synthesizes dataset
synth <- function(start_data, conf_data, var_order){
  # synthesize categorical first, then continuous
  visit_sequence = visit_sequence(var_order, start_data, type = "manual")
  roadmap = roadmap(conf_data, start_data, visit_sequence)
  recipe = construct_recipes(roadmap = roadmap)
  
  tree_cl <- parsnip::decision_tree(cost_complexity = .0001) %>%
    set_mode(mode = "classification") %>%
    set_engine(engine = "rpart")
  tree_reg <- parsnip::decision_tree(cost_complexity = .0001) %>%
    set_mode(mode = "regression") %>%
    set_engine(engine = "rpart")
  
  synth_algorithms = list()
  for (i in 1:length(var_order)){
    if(class(conf_data[,var_order[i]]) == "factor"){
      synth_algorithms[[i]] = tree_cl
    } else{
      synth_algorithms[[i]] = tree_reg
    }
  }

    synth_spec = synth_spec(roadmap,
                          synth_algorithms = synth_algorithms,
                          recipe,
                          predict_methods = sample_rpart)
  
  # noise
  noise <- noise(roadmap = roadmap,
                 add_noise = FALSE,
                 exclusions = 0)
  
  # constraints
  constraints <- constraints(roadmap = roadmap,
                             constraints = NULL,
                             max_z = 0)
  
  replicates <- replicates(replicates = 1,
                           workers = 1,
                           summary_function = NULL)
  
  # create a presynth object
  presynth1 <- presynth(
    roadmap = roadmap,
    synth_spec = synth_spec,
    noise = noise, 
    constraints = constraints,
    replicates = replicates
  )
  synthesized = synthesize(presynth1, progress = TRUE)
  synthesized
}
```

```{r}
# synthesize (poverty, from all input data)
conf_data = data_mi
start_data = data.frame("pov" = data_mi[,"pov"])
synth_pov_all <- synth(start_data, conf_data, c("SEX", "VETSTAT", "EMPSTAT", "EDUC", "HCOVANY", "BLACK", "FTOTINC", "AGE"))

# synthesize (poverty, from majority group only)
conf_data = data_mi %>%
  filter(pov == 0)
start_data = data.frame("pov" = as.factor(rep(0, nrow(data_mi))))
synth_pov_maj <- synth(start_data, conf_data, c("SEX", "VETSTAT", "EMPSTAT", "EDUC", "HCOVANY", "BLACK", "FTOTINC", "AGE"))

# apply permutation to dataset (need to add people in poverty back in)
synth_pov_maj <- synth_pov_maj$synthetic_data
synth_pov_maj$pov <- permute(data_mi$pov)
```

```{r}
calc_disc <- function(discriminator){
  # Evaluate discriminant-based metrics on the data using tree-based model
  tree_mod <- decision_tree(cost_complexity = tune()) %>%
    set_mode(mode = "classification") %>%
    set_engine(engine = "rpart")
  
  rpart_rec <- recipe(.source_label ~ ., data = discriminator$combined_data)
  
  grid = grid_regular(cost_complexity(), levels= 10)
  
  # set up discriminator
  d <- discriminator %>%
    add_propensities_tuned(
      grid = grid, 
      recipe = rpart_rec,
      spec = tree_mod
    )
  d
}
```

```{r}
disc_all = discrimination(synth_pov_all, data_mi)
res_all = calc_disc(disc_all)

disc_maj = discrimination(synth_pov_maj, data_mi)
res_maj = calc_disc(disc_maj)
```

```{r}
auc_all <- res_all %>%
  add_discriminator_auc()
auc_maj <- res_maj %>%
  add_discriminator_auc()

auc_all$discriminator_auc$.estimate[2]
auc_maj$discriminator_auc$.estimate[2]
```
The first number above is the AUC calculated from the synthetic and confidential dataset where the synthetic dataset was made using all of the input data. The second number is the AUC calculated from the synthetic and confidential dataset where the synthetic dataset was made using only the majority group. We can see that the AUC picks up a difference between the synthesis methods, where it's easier in general to discriminate between synthetic and confidential data when the synthetic data were created without using data from a minority group, which makes sense.

Diving a bit deeper into why we see this difference across datasets, we can compare propensity scores by our majority/minority split variable of interest.
```{r}
props = res_all$propensities
ggplot(props, aes(x = .pred_synthetic, group = as.factor(pov), color = as.factor(pov)))+
  geom_density()+
  theme_classic()+
  xlab("propensity score")+
  ggtitle("synthesized from all data")

props = res_maj$propensities
ggplot(props, aes(x = .pred_synthetic, group = as.factor(pov), color = as.factor(pov)))+
  geom_density()+
  theme_classic()+
  xlab("propensity score")+
  ggtitle("synthesized from majority only")
```

We can see in these plots that the synthetic data synthesized from the majority (people not in poverty) have a very different distribution of propensity scores compared to the synthetic data synthesized from all of the data. In general, the model is more confident about the placement of people in poverty (into synthetic or confidential) when the synthetic data were created from people not in poverty, reflecting the poor quality of the data for this subgroup. 

**EM: These graphs are really illustrative of your findings! This is defeinitely something I think you should highlight in a report or presentation of some sort!!**

Next, we look at discriminant-based metrics calculated by group on these models to investigate whether we can tell that some are a poor match to minority groups. I investigate only the discriminator AUC here.
```{r}
add_group_auc <- function(discrimination, group_var){
  discriminator_auc <- discrimination$propensities %>%
      dplyr::group_by(across(c(".sample", group_var)))%>%
      yardstick::roc_auc(".source_label", ".pred_synthetic") %>%
      dplyr::mutate(.sample = factor(.data$.sample, levels = c("training", "testing"))) %>%
      dplyr::arrange(.data$.sample) %>%
      dplyr::filter(.data$.sample == "testing") %>%
      dplyr::select(c(".estimate", group_var))
  discrimination$discriminator_auc <- discriminator_auc
  colnames(discrimination$discriminator_auc)[1] <- "discriminator_auc"
  return(discrimination)
}

res_all <- res_all %>%
  add_group_auc(group_var = "pov")
res_maj <- res_maj %>%
  add_group_auc(group_var = "pov")

gt(res_all$discriminator_auc) %>%
  tab_header("Synthetic data made using all data")
gt(res_maj$discriminator_auc) %>%
  tab_header("Synthetic data made using majority group only")
```

We can see here that people in poverty had much higher discriminator AUC values in the "bad" synthesis. 

In order to tell whether we expect differences in discriminator AUC close to the differences observed for the "good" synthetic dataset, I did a permutation test. I permuted the poverty indicator variable (the same permutation in the synthetic and confidential data), thus creating new majority/minority groups, re-ran the discriminator model, and re-calculated the group-specific AUC values. I then compared these values to my observed values.
```{r}
N = 10
n_minority = sum(data_mi$pov == 1)

min_auc = c()
maj_auc = c()

# N times:
for (i in 1:N){
  # Select randomly n rows of synthetic/confidential datasets, where n = number of people in poverty
  sample = permute(data_mi$pov)
  
  # Set up new pov indicator in confidential and synthetic data
  synth_sample = synth_pov_all$synthetic_data
  synth_sample$pov = sample
  
  conf_sample = data_mi
  conf_sample$pov = sample
  
  # Run discriminant-based metrics
  # Store the CART AUC values (just picking one metric to start) in two vectors, one for maj, one for min
  disc_sample = calc_disc(discrimination(synth_sample, conf_sample)) %>%
    add_group_auc(group_var = "pov")
  
  maj_auc = append(maj_auc, disc_sample$discriminator_auc$discriminator_auc[1])
  min_auc = append(min_auc, disc_sample$discriminator_auc$discriminator_auc[2])
}
```

```{r}
maj_auc
min_auc
maj_auc-min_auc
```
This approach shows that, if we were to split the data ("good" synthesis and confidential data) into random majority/minority groups of the same size as our actual majority/minority groups, we'd expect to see similar differences to what we observed.

**EM: I really like your permutation approach to test if the differences you found are "big" enough. What criterion did you use to determine whether the differences were "big" or not?**

So far, we've analyzed the extent to which the synthetic data appear to represent a specific minority group using a single model at a time. We've looked at: comparing discriminant-based metric values from several datasets to tell which dataset may do a better job in general; looking at graphs of propensity scores to show us whether the model is very confident about classifying a specific minority group; and calculating discriminant-based metrics by group using propensity scores from one model. We also looked at how to tell whether differences observed in these discriminant-based metrics by group are small or large using permutation tests.

However, we could also consider an approach where we fit two models, each on either the subset of synthetic and confidential data from the majority group, or the subset of these datasets from the minority group. We could then compare discriminant-based metrics to see whether the two models are able to discriminate well or poorly between the majority groups and minority groups without forcing these two models to be the same.

We look at this two-model approach using the "good" synthetic dataset.


```{r}
# Divide into four datasets -- synth min, synth maj, conf min, conf maj
conf_min = data_mi[data_mi$pov==1,]
synth_min = synth_pov_all$synthetic_data[synth_pov_all$synthetic_data$pov==1,]
conf_maj = data_mi[data_mi$pov==0,]
synth_maj = synth_pov_all$synthetic_data[synth_pov_all$synthetic_data$pov==0,]
  
# Run discriminant-based metrics on synth min vs conf min, synth maj vs conf maj
# Store the CART AUC values (just picking one metric to start) in two vectors, one for maj, one for min
# isolate to minority group
d_min <- discrimination(synth_min, conf_min)
d_tree_min <- calc_disc(d_min)
d_tree_min <- d_tree_min %>%
  add_discriminator_auc()
min_auc_pov_all = d_tree_min$discriminator_auc$.estimate[2]
  
# isolate to majority group
d_maj <- discrimination(synth_maj, conf_maj)
d_tree_maj <- calc_disc(d_maj)
d_tree_maj <- d_tree_maj %>%
  add_discriminator_auc()
maj_auc_pov_all = d_tree_maj$discriminator_auc$.estimate[2]
c(min_auc_pov_all, maj_auc_pov_all)
```

So we can see that, even in the "good" synthesis, we actually find it easier to discriminate between synthetic and confidential data for the minority group and the majority group. As before, we'll use a permutation test to figure out whether this difference is meaningful.

```{r}
# setup
N = 10
n_minority = sum(data_mi$pov == 1)

min_auc = c()
maj_auc = c()

# N times:
for (i in 1:N){
  # Select randomly n rows of synthetic/confidential datasets, where n = number of people in poverty
  sample = sample(x = 1:nrow(data_mi),
                  size = n_minority,
                  replace = FALSE)
  
  # Divide into four datasets -- synth min, synth maj, conf min, conf maj
  conf_min = data_mi[sample,]
  synth_min = synth_pov_all$synthetic_data[sample,]
  conf_maj = data_mi[-sample,]
  synth_maj = synth_pov_all$synthetic_data[-sample,]
  
  # Run discriminant-based metrics on synth min vs conf min, synth maj vs conf maj
  # Store the CART AUC values (just picking one metric to start) in two vectors, one for maj, one for min
  # isolate to minority group
  d_min <- discrimination(synth_min, conf_min)
  d_tree_min <- calc_disc(d_min)
  d_tree_min <- d_tree_min %>%
    add_discriminator_auc()
  min_auc = append(min_auc, d_tree_min$discriminator_auc$.estimate[2])

  # isolate to majority group
  d_maj <- discrimination(synth_maj, conf_maj)
  d_tree_maj <- calc_disc(d_maj)
  d_tree_maj <- d_tree_maj %>%
    add_discriminator_auc()
  maj_auc = append(maj_auc, d_tree_maj$discriminator_auc$.estimate[2])
}


min_auc-maj_auc
```

```{r}
min_auc
maj_auc
min_auc-maj_auc
```

We can see here that in random splits, the minority auc tends to actually be slightly smaller than the majority auc, meaning that the trend we saw even in the "good" synthesis was unexpected, since we observed that the minority auc was slightly larger than the majority auc. This two-model approach was the only method to suggest that our "good" synthesis might actually be biased towards the majority group as well. 

**EM: This result is really interesting. So a two-model approach may reveal more about the imbalance in utility than a single model which may overlook these differences. This information is something shareholders would definitely need to know. I'm wondering what characteristics of the minority and majority classes would make a two-model approach more necessary, and if all discriminant based utility metrics should implement this approach when dealing with majority and minority classes.**

I plan to look at ways to combat this, which include reordering our variables in the "good" synthesis to prioritize those most correlated with poverty status, in future work. Preliminary analyses have suggested it may be a viable method.

**EM: I definitely think this is a good idea!**

Overall, the research I have done so far suggests:
1) Tree-based models (single classification tree, random forest) are best at discriminating between synthetic and confidential data with known issues.
2) When using tree-based models for the discriminators, we can employ a pairwise approach to find continuous variables that differ between the synthetic and confidential datasets, but this approach generally does not work for categorical variables.
3) We can fit a single discriminator model on synthetic and confidential data and use a variety of measures to test whether the synthetic data have equal utility across majority/minority groups, including graphing propensity scores by group and calculating discriminant-based metrics by group. However, these methods are generally not as sensitive as a two-model approach.
4) We can use a two-model approach in which we fit different models on the subsets of synthetic/confidential data from the majority and minority group. Using this method is most sensitive to differences in utility by group, since it allows the models fit to the two groups to be different.

The major next steps for this work are to delve into the theory of specific discriminant-based metrics to ensure that the comparisons across groups are valid statistically and to look at this project with race rather than poverty as the majority/minority split variable. Since race is less strongly correlated with other variables in the dataset, it may have more subtle results than the poverty split. I also want to look at variable reordering as a way to counteract some of the biases that the two-model approach identified in the "good" synthetic dataset here. I hope to consider ways in which we might be able to identify subgroups on which models are most able to discriminate between synthetic and confidential data, to see if we can pull out minority groups that aren't being served well by a specific synthetic dataset rather than having to have a specific group in mind before we start the analysis. Finally, I hope to incorporate the pairwise and two-model approaches here into functions in syntheval.

**For your variable reordering step, I can share some of my preliminary analyses with you. I haven't gotten as far in the project, so everything is a little all over the place, but I think that could be a place for collaboration between the two of us.**




