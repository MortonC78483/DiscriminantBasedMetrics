---
title: "Correlation Exploration"
format:
  html:
    theme: default
  
---

In this document, I'm trying to understand how to make continuous and categorical datasets that I can compare in a meaningful way with discriminant-based metrics and tree-based models.

```{r}
library(sirt)
library(psych)
library(dplyr)
library(MASS)

library(ggplot2)
```

## Exploration of tetrachoric matrix
```{r}
set.seed(1)
x = c(rep(0,50), rep(1,50))#sample(c(0,1), 100,replace = T)
y = x #sample(c(0,1), 100,replace = T)

data = cbind(x, y)
(100*(sum(x==1 & y==1))-sum(x==1)*sum(y==1))/100^2
(100*(sum(x==0 & y==0))-sum(x==0)*sum(y==0))/100^2

tetrachoric2(data)$rho
var(data)
cor(data)
```

So we get the same values for our tetrachoric correlation and our underlying correlation.

```{r}
set.seed(1)
x = c(rep(0,50), rep(1,50))#sample(c(0,1), 100,replace = T)
y = x #sample(c(0,1), 100,replace = T)
z = sample(c(0,1), 100, replace = 1)

data = cbind(x, y, z)
print("variance")
(100*(sum(x==1 & y==1))-sum(x==1)*sum(y==1))/100^2
(100*(sum(x==0 & y==0))-sum(x==0)*sum(y==0))/100^2

print("tetrachoric")
tetrachoric2(data)$rho

print("correlation")
cor(data)
```
Tetrachoric and correlation matrices can be different. It's not clear to me why they're different here.

```{r}
set.seed(1)
xn = rnorm(100)
yn = rnorm(100)

datan = cbind(xn,yn)

x = xn>0
y = yn>0
data = cbind(x,y)

print("underlying mv normal")
cor(datan)

print("tetrachoric")
tetrachoric2(data)$rho

print("correlation")
cor(data)
```
When we have a small number of data points, tetrachoric is more off than correlation to the underlying data.

```{r}
set.seed(1)
xn = rnorm(10000)
yn = xn
zn = rnorm(10000) + xn
datan = cbind(xn,yn,zn)

x = xn>0
y = yn>0
z = zn>0
data = cbind(x,y, z)

cor(datan)
tetrachoric2(data)$rho
cor(data)
```
But for larger datasets, tetrachoric is much more similar to the underlying normal distribution's correlation matrix.

## Insights about categorical-continuous comparison
So, I think that what we can do to make categorical datasets that are similar to our continuous datasets, for comparison purposes, is to create underlying m.v. normals, which we use for the continuous data, then threshold all of the variables (above 0 -> 1, below 0 -> 0) and use these thresholded values to be our categorical data. I would say this comparison is valid by evaluating the tetrachoric matrix of the categorical data, which generally matches the correlation matrix of the underlying m.v. normal data, because that's what it is designed to do.

## Making the datasets I want
For this project, there are a few different datasets I want to make to compare model types with. I'm going to try to make all of them here to see if the tetrachoric and correlation matrices are sort of matching what I think they should be.
a) Confidential and synthetic dataset are drawn from (for continuous) multivariate normal with known variance-covariance matrix, and from (for categorical) known distribution. Control pairing to test which hyperparameters work best in continuous vs. categorical “ideal” setting.
```{r}
generate_cat <- function(cont){
  matrix(as.numeric(cont>0), 
             nrow = nrow(cont))
}

set.seed(1)
n=10000 # number of samples
corr=.7 # correlation
p = 10 # number of variables
vcov = matrix(corr, p, p) + diag(1-corr, p, p) # vcov matrix, p on all off-diagonal variables
means = rep(0,p) # mean vector
conf_cont1 = mvrnorm(means, vcov, n = n)
synth_cont1 = mvrnorm(means, vcov, n = n)

conf_cat1 = generate_cat(conf_cont1)
synth_cat1 = generate_cat(synth_cont1)

# comparing the variances
cor(conf_cont1)
cor(synth_cont1)

tetrachoric2(conf_cat1)$rho
tetrachoric2(synth_cat1)$rho
```

b) Confidential data are drawn from (for continuous) multivariate normal with known variance-covariance matrix, and from (for categorical) known distribution. Synthetic data are drawn from distribution with larger variances and slightly (~20%) off means.
```{r}
vcov = matrix(corr, p, p) + diag(1-corr, p, p) # vcov matrix, p on all off-diagonal variables
means = rep(0,p) # mean vector
conf_cont1 = mvrnorm(means, vcov, n = n)
means = sample(c(-.2,.2), 10, replace = T) # mean vector
vcov = matrix(2*corr, p, p) + diag(4-2*corr, p, p) # vcov matrix, p on all off-diagonal variables
synth_cont1 = mvrnorm(means, vcov, n = n)

conf_cat1 = generate_cat(conf_cont1)
synth_cat1 = generate_cat(synth_cont1)

# comparing the variances
cor(conf_cont1)
cor(synth_cont1)

tetrachoric2(conf_cat1)$rho
tetrachoric2(synth_cat1)$rho


ggplot(data.frame(conf_cont1), aes(x=X1, y=X2))+
  geom_point()+
  theme_classic()
ggplot(data.frame(synth_cont1), aes(x = X1, y = X2))+
  geom_point()+
  theme_classic()
```

c) Confidential dataset is multivariate normal or has a known joint categorical distribution, and the synthetic dataset has a known mismatch in distributional coverage. One variable for the continuous dataset will be centered at a different value in the synthetic vs. confidential data, and one variable for the categorical dataset will have a drastically different distribution across categories in the synthetic vs. confidential data. Pairing to test whether methods are able to pick up this mismatch and on which types of datasets.
```{r}
vcov = matrix(corr, p, p) + diag(1-corr, p, p) # vcov matrix, p on all off-diagonal variables
means = rep(0,p) # mean vector
conf_cont1 = mvrnorm(means, vcov, n = n)
means[1] = 3
synth_cont1 = mvrnorm(means, vcov, n = n)

conf_cat1 = generate_cat(conf_cont1)
synth_cat1 = generate_cat(synth_cont1)

# comparing the variances
cor(synth_cat1)

tetrachoric2(synth_cat1)$rho

ggplot(data.frame(conf_cont1), aes(x = X1))+
  geom_histogram()+
  geom_histogram(data = data.frame(synth_cont1), aes(x = X1), fill = "red", alpha = .5)
```
In this section, we see that for the first time, the tetrachoric correlation matrix doesn't match the correlation matrix of the underlying normal distribution. If we did the thresholding at 3 for X1, then the tetrachoric correlation matrix would match the underlying correlation matrix, but obviously now the synthetic and confidential datasets would be the same at this point because we've centered the 0's and 1's. So I'm not sure, in this pairing of datasets, how to make sure that the synthetic and confidential datasets have different means without affecting tetrachoric correlation. It seems to be most affected at the extremes of the data, so only when we make the mean of our incorrect variable really high (3) compared to standard deviation (1). I think to get around this, I'll set the mean at 2.

```{r}
vcov = matrix(corr, p, p) + diag(1-corr, p, p) # vcov matrix, p on all off-diagonal variables
means = rep(0,p) # mean vector
conf_cont1 = mvrnorm(means, vcov, n = n)
means[1] = 2
synth_cont1 = mvrnorm(means, vcov, n = n)

conf_cat1 = generate_cat(conf_cont1)
synth_cat1 = generate_cat(synth_cont1)

# comparing the variances
cor(conf_cont1)
cor(synth_cont1)

tetrachoric2(conf_cat1)$rho
tetrachoric2(synth_cat1)$rho

ggplot(data.frame(conf_cont1), aes(x=X1, y=X2))+
  geom_point()+
  theme_classic()
ggplot(data.frame(synth_cont1), aes(x = X1, y = X2))+
  geom_point()+
  theme_classic()

ggplot(data.frame(conf_cont1), aes(x = X1))+
  geom_histogram()+
  geom_histogram(data = data.frame(synth_cont1), aes(x = X1), fill = "red", alpha = .5)
```

d) A relationship between two variables is reversed in the confidential vs. synthetic datasets. Pairing to test whether methods can pick up that there is an incorrect association between two variables.
```{r}
vcov = matrix(corr, p, p) + diag(1-corr, p, p) # vcov matrix, p on all off-diagonal variables
means = rep(0,p) # mean vector
conf_cont1 = mvrnorm(means, vcov, n = n)
vcov[1,2:p] = -rep(corr, p-1)
vcov[2:p,1] = -rep(corr, p-1)
synth_cont1 = mvrnorm(means, vcov, n = n)

conf_cat1 = generate_cat(conf_cont1)
synth_cat1 = generate_cat(synth_cont1)

# comparing the variances
cor(conf_cont1)
cor(synth_cont1)

tetrachoric2(conf_cat1)$rho
tetrachoric2(synth_cat1)$rho

ggplot(data.frame(conf_cont1), aes(x=X1, y=X2))+
  geom_point()+
  theme_classic()
ggplot(data.frame(synth_cont1), aes(x = X1, y = X2))+
  geom_point()+
  theme_classic()
```

## Not complete yet
e) A relationship between one variable and many other variables reverses and/or becomes more random at specific values of the variable. The categorical confidential data will generally match the synthetic data less for a specific category in a certain categorical variable, while the continuous confidential data will generally match the synthetic data less as one of the continuous variables gets smaller. This pairing tests which models might be able to be used to identify when a specific subgroup of the population has synthetic data of lower utility than the rest of the population.
```{r}
vcov = matrix(corr, p, p) + diag(1-corr, p, p) # vcov matrix, p on all off-diagonal variables
means = rep(0,p) # mean vector
conf_cont1 = mvrnorm(means, vcov, n = n)
vcov[1,2:p] = -rep(corr, p-1)
vcov[2:p,1] = -rep(corr, p-1)
synth_cont1 = mvrnorm(means, vcov, n = n)

conf_cat1 = generate_cat(conf_cont1)
synth_cat1 = generate_cat(synth_cont1)

# comparing the variances
cor(conf_cont1)
cor(synth_cont1)

tetrachoric2(conf_cat1)$rho
tetrachoric2(synth_cat1)$rho

ggplot(data.frame(conf_cont1), aes(x=X1, y=X2))+
  geom_point()+
  theme_classic()
ggplot(data.frame(synth_cont1), aes(x = X1, y = X2))+
  geom_point()+
  theme_classic()
```


















